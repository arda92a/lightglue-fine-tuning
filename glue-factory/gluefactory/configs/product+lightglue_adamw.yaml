# Product Matching with LightGlue - AdamW Fine-tune Config
# Uses AdamW optimizer with weight decay for better regularization
# Longer training with delayed LR decay

data:
    name: product_pairs
    data_dir: lightglue_dataset_final
    image_dir: images/
    annotation_dir: annotations/
    matches_file: matches.json
    
    # Split ratios (must sum to 1.0)
    train_ratio: 0.7
    val_ratio: 0.2
    test_ratio: 0.1
    
    # Image settings
    grayscale: false
    resize: [640, 480]
    
    # Product settings
    embedding_dim: 128
    max_products: 400
    pad_products: true
    batch_size: 8

model:
    name: two_view_pipeline
    
    extractor:
        name: null
    
    ground_truth:
        name: null
    
    matcher:
        name: matchers.lightglue
        input_dim: 128
        descriptor_dim: 256
        n_layers: 9
        num_heads: 4
        flash: false
        checkpointed: true
        filter_threshold: 0.25
        
        weights: disk
        weights_from_version: v0.1_arxiv
        
        loss:
            gamma: 1.0
            fn: nll
            nll_balancing: 0.5

train:
    seed: 42
    epochs: 30                       # Aynı epoch sayısı
    batch_size: 8
    num_workers: 4
    
    log_every_iter: 50
    eval_every_iter: 50
    
    optimizer: adamw                 # AdamW optimizer
    optimizer_options:
        weight_decay: 0.01           # Weight decay for regularization (overfitting azaltır)
    
    lr: 5e-5                         # Aynı LR
    lr_schedule:
        start: 15                    # Aynı schedule
        type: exp
        on_epoch: true
        exp_div_10: 10

    plot: null
